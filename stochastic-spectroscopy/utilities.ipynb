{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import gpflow\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['model_to_h5', 'h5_to_model', 'make_batch_iter', 'setup_logger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_in(t, F):\n",
    "    flag = True\n",
    "    if F is None:\n",
    "        return flag\n",
    "    for f in F:\n",
    "        if f in t:\n",
    "            flag = False\n",
    "        else:\n",
    "            continue\n",
    "    return flag\n",
    "\n",
    "def model_to_h5(fname, save_dir, model):\n",
    "    param_dict = gpflow.utilities.parameter_dict(model)\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    full_path = str((Path(save_dir) / Path(fname)).absolute())\n",
    "    # clean the dictionary, converting all parameters to constrained values in numpy form\n",
    "    # we lose information on the transform or prior. But if the model can be reproduced with\n",
    "    # blank parameters, we just want to \n",
    "    with h5py.File(full_path, 'w') as fid:\n",
    "        for k, v in param_dict.items():\n",
    "            fid.create_dataset(k, data=v.numpy())\n",
    "            \n",
    "def h5_to_model(fname, save_dir, model, filter_keys=None):\n",
    "    # a modle must be instantiated with the same structure as indicated by the keys in the h5py file\n",
    "    full_path = Path(save_dir) / Path(fname)\n",
    "    assert full_path.exists(), f\"could not find {str(full_path.absolute())}\"\n",
    "    param_dict = {}\n",
    "    with h5py.File(str(full_path.absolute()), 'r') as fid:\n",
    "        keys = fid.keys()\n",
    "        for key in keys:\n",
    "            if none_in(key, filter_keys):\n",
    "                param_dict[key] = tf.convert_to_tensor(fid[key])\n",
    "        gpflow.utilities.multiple_assign(model, param_dict)        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def make_batch_iter(data, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        data_minibatch = (\n",
    "        tf.data.Dataset.from_tensor_slices(data)\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                        .repeat()\n",
    "                        .shuffle(data[0].shape[0])\n",
    "                        .batch(batch_size)\n",
    "                        )\n",
    "    else:\n",
    "        data_minibatch = (\n",
    "        tf.data.Dataset.from_tensor_slices(data)\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                        .repeat()\n",
    "                        .batch(batch_size)\n",
    "                        )\n",
    "    data_minibatch_it = iter(data_minibatch)\n",
    "    return data_minibatch_it\n",
    "\n",
    "def setup_logger(model, name, loss_fn, log_dir='./logs'):\n",
    "    log_dir = Path(log_dir) / Path(name)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fast_tasks = gpflow.monitor.MonitorTaskGroup([gpflow.monitor.ModelToTensorBoard(str(log_dir), model),\n",
    "                                                 gpflow.monitor.ScalarToTensorBoard(str(log_dir), loss_fn, \"loss\")],\n",
    "                                                period=1)\n",
    "    monitor = gpflow.monitor.Monitor(fast_tasks)\n",
    "    return monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
